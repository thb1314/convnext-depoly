{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import os\n",
    "import ctypes\n",
    "# cuda: https://nvidia.github.io/cuda-python/\n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import pycuda.autoinit\n",
    "\n",
    "soFile = \"./layernorm_plugin.so\"\n",
    "epsilon = 1.0e-2\n",
    "np.random.seed(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6559984",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = trt.Logger(trt.Logger.ERROR)\n",
    "trt.init_libnvinfer_plugins(logger, '')\n",
    "ctypes.cdll.LoadLibrary(soFile)\n",
    "soFile = \"./gelu.so\"\n",
    "ctypes.cdll.LoadLibrary(soFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soFile = \"./layernorm_chfirst_plugin.so\"\n",
    "ctypes.cdll.LoadLibrary(soFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "    \n",
    "    def free(self):\n",
    "        self.host = None\n",
    "        if self.device is not None:\n",
    "            self.device.free()\n",
    "            self.device = None\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.free()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    \n",
    "# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\n",
    "def allocate_buffers(ori_inputs, ori_outputs, engine, context, stream):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    nInput = np.sum([engine.binding_is_input(i) for i in range(engine.num_bindings)])\n",
    "    \n",
    "    for i, binding in enumerate(engine):\n",
    "        size = trt.volume(context.get_binding_shape(i))\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        try:\n",
    "            if engine.binding_is_input(binding):\n",
    "                ori_mem = ori_inputs[i]\n",
    "            else:\n",
    "                ori_mem = ori_outputs[i - nInput]\n",
    "        except:\n",
    "            ori_mem = None\n",
    "            \n",
    "        if ori_mem is not None:\n",
    "            if ori_mem.host.nbytes >= size:\n",
    "                host_mem = ori_mem.host\n",
    "                device_mem = ori_mem.device\n",
    "                # 避免再次释放\n",
    "                ori_mem.device = None\n",
    "            else:\n",
    "                ori_mem.free()\n",
    "                host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "                device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        else:\n",
    "            # Allocate host and device buffers\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        # Append the device buffer to device bindings.\n",
    "        bindings.append(int(device_mem))\n",
    "        # Append to the appropriate list.\n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        else:\n",
    "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    return inputs, outputs, bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ac5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engine(onnx_file_path, enable_fp16 = False, max_batch_size = 256, max_workspace_size = 10, write_engine=True):\n",
    "    # 通过加载onnx文件，构建engine\n",
    "    # :param onnx_file_path: onnx文件路径\n",
    "    # :return: engine\n",
    "    G_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    \n",
    "    explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    with trt.Builder(G_LOGGER) as builder, builder.create_network(explicit_batch) as network, \\\n",
    "            trt.OnnxParser(network, G_LOGGER) as parser:\n",
    "        \n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, GiB(max_workspace_size))\n",
    "        if enable_fp16:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "        print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "        with open(onnx_file_path, 'rb') as model:\n",
    "            print('Beginning ONNX file parsing')\n",
    "            parser.parse(model.read())\n",
    "        print('Completed parsing of ONNX file')\n",
    "        print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "        # 重点\n",
    "        profile = builder.create_optimization_profile()\n",
    "        profile.set_shape(\"input\", (1, 3, 224, 224), (max_batch_size, 3, 224, 224), (max_batch_size, 3, 224, 224))\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "        serialized_engine = builder.build_serialized_network(network, config)\n",
    "        print(\"Completed creating Engine\")\n",
    "        # 保存engine文件\n",
    "        if write_engine:\n",
    "            \n",
    "            onnx_path = os.path.realpath(onnx_file_path) \n",
    "            engine_file_path = \".\".join(onnx_path.split('.')[:-1] + ['trt'])\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(serialized_engine)\n",
    "        return serialized_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d602d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is generalized for multiple inputs/outputs.\n",
    "# inputs and outputs are expected to be lists of HostDeviceMem objects.\n",
    "def do_inference(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRTClassify(object):\n",
    "    def __init__(self, engine_path):\n",
    "        self.engine_path = engine_path\n",
    "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
    "        self.engine = self._get_engine()\n",
    "        self.context = self.engine.create_execution_context()\n",
    "        self.stream = cuda.Stream()\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "\n",
    "    def _get_engine(self):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        f = open(self.engine_path, 'rb')\n",
    "        runtime = trt.Runtime(self.logger)\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "\n",
    "    def detect(self, image_np_array, cuda_ctx = pycuda.autoinit.context):\n",
    "        if cuda_ctx:\n",
    "            cuda_ctx.push()\n",
    "\n",
    "        batch_size = image_np_array.shape[0]\n",
    "        # 动态输入\n",
    "        origin_inputshape = self.context.get_binding_shape(0)\n",
    "        origin_inputshape[0] = batch_size\n",
    "        self.context.set_binding_shape(0, (origin_inputshape))\n",
    "        self.context.set_optimization_profile_async(0, self.stream.handle)\n",
    "        \n",
    "        self.inputs, self.outputs, bindings = allocate_buffers(self.inputs, self.outputs, self.engine, self.context, self.stream)\n",
    "        np_type = trt.nptype(self.engine.get_binding_dtype(0))\n",
    "        # Do inference\n",
    "        self.inputs[0].host = np.ascontiguousarray(image_np_array.astype(np_type))\n",
    "        trt_outputs = do_inference(self.context, bindings=bindings, inputs=self.inputs, outputs=self.outputs,\n",
    "                                          stream=self.stream)\n",
    "        \n",
    "        if cuda_ctx:\n",
    "            cuda_ctx.pop()\n",
    "        \n",
    "        nInput = np.sum([self.engine.binding_is_input(i) for i in range(self.engine.num_bindings)])\n",
    "        nOutput = self.engine.num_bindings - nInput\n",
    "        for i in range(nOutput):\n",
    "            shape = self.context.get_binding_shape(nInput + i)\n",
    "            trt_outputs[i] = trt_outputs[i].reshape(shape)\n",
    "        return trt_outputs\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.detect(x)\n",
    "    \n",
    "    def __del__(self):\n",
    "        del self.inputs\n",
    "        del self.outputs\n",
    "        del self.stream\n",
    "        del self.engine\n",
    "        del self.context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78313c9",
   "metadata": {},
   "source": [
    "## 融合Gelu试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_graphsurgeon as gs\n",
    "import onnx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_graph = onnx.load('convnext_tiny_rm_gamma_rep_layernorm_gs.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed22e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_gs_graph = gs.import_onnx(onnx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b539188",
   "metadata": {},
   "outputs": [],
   "source": [
    "gelu_idx = 0\n",
    "for node in onnx_gs_graph.nodes:\n",
    "    \n",
    "    # 替换gamma\n",
    "    if node.op != 'Add':\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        mul_node = node.o(1)\n",
    "    except:\n",
    "        continue\n",
    "    if mul_node.op != 'Mul':\n",
    "        continue\n",
    "    \n",
    "    # mul 0.5 node\n",
    "    mul_node = mul_node.o(0)\n",
    "    \n",
    "    if mul_node.op != 'Mul':\n",
    "        continue\n",
    "    \n",
    "    gelu_idx += 1\n",
    "    gelu_name = 'Gelu-%d' % gelu_idx\n",
    "    gelu_node = gs.Node('Gelu', name=gelu_name, inputs = node.outputs[0:1], outputs = mul_node.outputs[0:1])\n",
    "    \n",
    "    mul_node.outputs.clear()\n",
    "#     node.inputs.clear()\n",
    "    onnx_gs_graph.nodes.append(gelu_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_gs_graph = onnx_gs_graph.cleanup().toposort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(gs.export_onnx(onnx_gs_graph), \"convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny.onnx\" --workspace=11000 --saveEngine=convnext_tiny.trt --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.trt --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117f7a4",
   "metadata": {},
   "source": [
    "## layernorm剩余"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272a44f",
   "metadata": {},
   "source": [
    "首先查看目前模型融合情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from trex import *\n",
    "\n",
    "# Configure a wider output (for the wide graphs)\n",
    "set_wide_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = EnginePlan('./layer.json', './profile.json', './profile.metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = layer_type_formatter if True else precision_formatter\n",
    "graph = to_dot(plan, formatter)\n",
    "svg_name = render_dot(graph, 'convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.engine', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_graphsurgeon as gs\n",
    "import onnx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_graph = onnx.load('convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx')\n",
    "onnx_gs_graph = gs.import_onnx(onnx_graph)\n",
    "\n",
    "# 合并LayeNorm\n",
    "layernorm_idx = 0\n",
    "for node in onnx_gs_graph.nodes:\n",
    "    \n",
    "    if node.op != 'ReduceMean':\n",
    "        continue\n",
    "    try:\n",
    "        sub_nodes = list()\n",
    "        for i in range(2):\n",
    "            sub_nodes.append(node.o(i))\n",
    "    except:\n",
    "        pass\n",
    "    if not sub_nodes or sub_nodes[0].op != 'Sub':\n",
    "        continue\n",
    "    \n",
    "    div_node = None\n",
    "    pow_node = None\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node.op != 'Sub':\n",
    "            continue\n",
    "        try:\n",
    "            for i in range(2):\n",
    "                tmp_node = sub_node.o(i)\n",
    "                if tmp_node.op == \"Div\":\n",
    "                    div_node = tmp_node\n",
    "                elif tmp_node.op == \"Pow\":\n",
    "                    pow_node = tmp_node\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if div_node is None or pow_node is None:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        mul_node = div_node.o(0)\n",
    "    except:\n",
    "        continue\n",
    "    if mul_node.op != 'Mul':\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        add_node = mul_node.o(0)\n",
    "    except:\n",
    "        continue\n",
    "    if add_node.op != 'Add':\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    eps_node = pow_node.o(0).o(0)\n",
    "    eps = eps_node.inputs[1].inputs[0].attrs['value'].values\n",
    "    try:\n",
    "        weight = mul_node.inputs[1].values\n",
    "    except:\n",
    "        weight = mul_node.inputs[0].values\n",
    "        \n",
    "    try:\n",
    "        bias = add_node.inputs[0].values\n",
    "    except:\n",
    "        bias = add_node.inputs[1].values\n",
    "    \n",
    "    data_format = \"channels_last\" if int(node.attrs['axes'][0]) == -1 else \"channels_first\"\n",
    "    if data_format != \"channels_first\":\n",
    "        continue\n",
    "    attrs = {\n",
    "        'data_format':data_format,\n",
    "        'eps':float(eps)\n",
    "    }\n",
    "    \n",
    "    # 创造transpose节点\n",
    "    layernorm_idx += 1\n",
    "    layernorm_name = 'LayerNorm-CHFirst-%d' % layernorm_idx\n",
    "    print('layernorm_name', layernorm_name)\n",
    "    \n",
    "    pre_transpose_name = 'PreTranspose-%d' % layernorm_idx\n",
    "    pre_transpose_output = gs.Variable(name = pre_transpose_name + '_output')\n",
    "    pre_transpose_node = gs.Node('Transpose', name=pre_transpose_name, attrs={'perm':np.int64([0,2,3,1])}, inputs = node.inputs[0:1], outputs = [pre_transpose_output])\n",
    "    \n",
    "    layernorm_output = gs.Variable(name = layernorm_name + '_output')\n",
    "    weight_const = gs.Constant(name=layernorm_name+ \"_weight\", values=weight.reshape(-1))\n",
    "    bias_const = gs.Constant(name=layernorm_name+ \"_bias\", values=bias.reshape(-1))\n",
    "    new_layernorm_node = gs.Node('LayerNorm', name=layernorm_name, attrs=attrs, inputs = [pre_transpose_output, weight_const, bias_const], outputs = [layernorm_output])\n",
    "    \n",
    "    post_transpose_name = 'PostTranspose-%d' % layernorm_idx\n",
    "    post_transpose_output = gs.Variable(name = post_transpose_name + '_output')\n",
    "    post_transpose_node = gs.Node('Transpose', name=post_transpose_name, attrs={'perm':np.int64([0,3,1,2])}, inputs = [layernorm_output], outputs = add_node.outputs[0:1])\n",
    "\n",
    "\n",
    "    add_node.outputs.clear()\n",
    "    node.inputs.clear()\n",
    "    sub_node.inputs.clear()\n",
    "    onnx_gs_graph.nodes.append(new_layernorm_node)\n",
    "    onnx_gs_graph.nodes.append(pre_transpose_node)\n",
    "    onnx_gs_graph.nodes.append(post_transpose_node)\n",
    "    \n",
    "\n",
    "onnx_gs_graph = onnx_gs_graph.cleanup().toposort()\n",
    "onnx.save(gs.export_onnx(onnx_gs_graph), \"convnext_tiny_rm_gamma_rep_layernorm_gs_2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gs_2.onnx\" --workspace=11000 --dumpRefit --dumpProfile --profilingVerbosity=detailed --dumpLayerInfo --exportLayerInfo=layer.json --exportProfile=profile.json --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gs_2.engine --verbose --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\"\n",
    "        \n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_fuse_gamma.onnx\" --workspace=11000 --dumpRefit --dumpProfile --profilingVerbosity=detailed --dumpLayerInfo --exportLayerInfo=layer.json --exportProfile=profile.json --saveEngine=convnext_tiny_fuse_gamma.trt --verbose --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f75a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_graph = onnx.load('convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx')\n",
    "onnx_gs_graph = gs.import_onnx(onnx_graph)\n",
    "\n",
    "# 合并LayeNorm\n",
    "layernorm_idx = 0\n",
    "for node in onnx_gs_graph.nodes:\n",
    "    \n",
    "    if node.op != 'ReduceMean':\n",
    "        continue\n",
    "    try:\n",
    "        sub_nodes = list()\n",
    "        for i in range(2):\n",
    "            sub_nodes.append(node.o(i))\n",
    "    except:\n",
    "        pass\n",
    "    if not sub_nodes or sub_nodes[0].op != 'Sub':\n",
    "        continue\n",
    "    \n",
    "    div_node = None\n",
    "    pow_node = None\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node.op != 'Sub':\n",
    "            continue\n",
    "        try:\n",
    "            for i in range(2):\n",
    "                tmp_node = sub_node.o(i)\n",
    "                if tmp_node.op == \"Div\":\n",
    "                    div_node = tmp_node\n",
    "                elif tmp_node.op == \"Pow\":\n",
    "                    pow_node = tmp_node\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if div_node is None or pow_node is None:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        mul_node = div_node.o(0)\n",
    "    except:\n",
    "        continue\n",
    "    if mul_node.op != 'Mul':\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        add_node = mul_node.o(0)\n",
    "    except:\n",
    "        continue\n",
    "    if add_node.op != 'Add':\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    eps_node = pow_node.o(0).o(0)\n",
    "    eps = eps_node.inputs[1].inputs[0].attrs['value'].values\n",
    "    try:\n",
    "        weight = mul_node.inputs[1].values\n",
    "    except:\n",
    "        weight = mul_node.inputs[0].values\n",
    "        \n",
    "    try:\n",
    "        bias = add_node.inputs[0].values\n",
    "    except:\n",
    "        bias = add_node.inputs[1].values\n",
    "    \n",
    "    data_format = \"channels_last\" if int(node.attrs['axes'][0]) == -1 else \"channels_first\"\n",
    "    if data_format != \"channels_first\":\n",
    "        continue\n",
    "    attrs = {\n",
    "        'data_format':data_format,\n",
    "        'eps':float(eps)\n",
    "    }\n",
    "    \n",
    "    # 创造transpose节点\n",
    "    layernorm_idx += 1\n",
    "    layernorm_name = 'LayerNorm_CHFirst-%d' % layernorm_idx\n",
    "    print('layernorm_name', layernorm_name)\n",
    "    \n",
    "    weight_const = gs.Constant(name=layernorm_name+ \"_weight\", values=weight.reshape(-1))\n",
    "    bias_const = gs.Constant(name=layernorm_name+ \"_bias\", values=bias.reshape(-1))\n",
    "    new_layernorm_node = gs.Node('LayerNorm_CHFirst', name=layernorm_name, attrs=attrs, inputs = [node.inputs[0], weight_const, bias_const], outputs = add_node.outputs[0:1])\n",
    "    \n",
    "    add_node.outputs.clear()\n",
    "    node.inputs.clear()\n",
    "    sub_node.inputs.clear()\n",
    "    onnx_gs_graph.nodes.append(new_layernorm_node)\n",
    "    \n",
    "\n",
    "onnx_gs_graph = onnx_gs_graph.cleanup().toposort()\n",
    "onnx.save(gs.export_onnx(onnx_gs_graph), \"convnext_tiny_rm_gamma_rep_layernorm_gs_3.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7141da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from trex import *\n",
    "\n",
    "# Configure a wider output (for the wide graphs)\n",
    "set_wide_display()\n",
    "\n",
    "plan = EnginePlan('./layer.json', './profile.json', './profile.metadata.json')\n",
    "\n",
    "formatter = layer_type_formatter if True else precision_formatter\n",
    "graph = to_dot(plan, formatter)\n",
    "svg_name = render_dot(graph, 'convnext_tiny_rm_gamma_rep_layernorm_gelu_gs_2.engine', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gs_3.onnx\" --workspace=11000 --dumpRefit --dumpProfile --profilingVerbosity=detailed --dumpLayerInfo --exportLayerInfo=layer.json --exportProfile=profile.json --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gs_3.engine --verbose --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead366ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from trex import *\n",
    "\n",
    "# Configure a wider output (for the wide graphs)\n",
    "set_wide_display()\n",
    "\n",
    "plan = EnginePlan('./layer.json', './profile.json', './profile.metadata.json')\n",
    "\n",
    "formatter = layer_type_formatter if True else precision_formatter\n",
    "graph = to_dot(plan, formatter)\n",
    "svg_name = render_dot(graph, 'convnext_tiny_rm_gamma_rep_layernorm_gs_3.engine', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eca013",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx\" --workspace=11000 --dumpRefit --dumpProfile --profilingVerbosity=detailed --dumpLayerInfo --exportLayerInfo=layer.json --exportProfile=profile.json --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.trt --verbose --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\"\n",
    "        \n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny.onnx\" --workspace=11000 --saveEngine=convnext_tiny.trt --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d578f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gs.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gs.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_cls_object = TRTClassify('./convnext_tiny.trt')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_fuse_gamma.trt')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.trt')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "\n",
    "inputs = np.random.rand(256,3,224,224).astype(np.float32)\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_2.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_3.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gs_2.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gs_2-fp16.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\" --fp16\n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gs_3.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gs_3-fp16.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\" --fp16\n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_fuse_gamma.onnx\" --workspace=11000 --saveEngine=convnext_tiny_fuse_gamma-fp16.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\" --fp16\n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.onnx\" --workspace=11000 --saveEngine=convnext_tiny_rm_gamma_rep_layernorm_gelu_gs-fp16.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\" --fp16\n",
    "!trtexec --minShapes=input:1x3x224x224 --maxShapes=input:256x3x224x224 --optShapes=input:256x3x224x224 --onnx=\"./convnext_tiny.onnx\" --workspace=11000 --saveEngine=convnext_tiny-fp16.engine --plugins=\"gelu.so\" --plugins=\"layernorm_plugin.so\" --plugins=\"layernorm_chfirst_plugin.so\" --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac798898",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.rand(256,3,224,224).astype(np.float32)\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_2-fp16')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_3-fp16.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_fuse_gamma-fp16.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs-fp16.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object\n",
    "\n",
    "trt_cls_object = TRTClassify('./convnext_tiny-fp16.engine')\n",
    "for i in range(100):\n",
    "    trt_cls_object(inputs)\n",
    "%timeit trt_cls_object(inputs)\n",
    "del trt_cls_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6966e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123eee56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d1c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98def913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
